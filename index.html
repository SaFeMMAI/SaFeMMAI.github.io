<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Workshop on Safe and Trustworthy Multimodal AI Systems at ICCV2025">
    <title>Workshop on Safe and Trustworthy Multimodal AI Systems (SaFeMM-AI) - ICCV2025</title>
    <link rel="stylesheet" href="styles.css">
    <!-- Add icon library -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="icon" href="resources/favicon_safemmai.png" type="image/png">
</head>
<body>

    <!-- Navigation bar -->
    <nav class="navbar">
        <div class="container" style="width: 95%;">
            <div class="logo-title">
                <img src="resources/iccv-navbar-logo.svg" alt="Logo" class="logo">
                <h3 class="title">ICCV2025 SaFeMM-AI Workshop</h3>
            </div>

            <div class="navlist">
                <ul>
                    <li><a href="#introduction">Introduction</a></li>
                    <li><a href="#important-dates">Important Dates</a></li>
                    <li><a href="#schedule">Schedule</a></li>
                    <li><a href="#speaker">Speakers</a></li>
                    <li><a href="#papers">Accepted Papers</a></li>
                    <li><a href="#committee">Organizers</a></li>
                    <li><a href="#contact">Contact</a></li>
                    <li><a href="#sponsorship">Sponsors</a></li>
                </ul>
            </div>

            <div class="dropdown">
                <button onclick="myFunction(event)" class="dropbtn"><i class="fa fa-bars"></i></button>
                <div id="myDropdown" class="dropdown-content">
                    <li><a href="#introduction" onclick="Close()">Introduction</a></li>
                    <li><a href="#important-dates" onclick="Close()">Important Dates</a></li>
                    <li><a href="#schedule" onclick="Close()">Schedule</a></li>
                    <li><a href="#speaker" onclick="Close()">Speakers</a></li>
                    <li><a href="#papers" onclick="Close()">Accepted Papers</a></li>
                    <li><a href="#committee" onclick="Close()">Organizers</a></li>
                    <li><a href="#contact" onclick="Close()">Contact</a></li>
                    <li><a href="#sponsorship" onclick="Close()">Sponsors</a></li>
                </div>
              </div>

        </div>
    </nav>

    <!-- Cover image with title -->
    <section class="cover">
        <img src="resources/cover-safemm_3.png" alt="Cover Image" class="cover-image">
        <div class="cover-text">
            <h1 style="font-size: 2.5rem; white-space: nowrap; color:#1D3C5E">SaFeMM-AI: Safe and Trustworthy Multimodal AI Systems</h1>
            <h1 style="font-size: 1.2rem; margin-top: 1rem; color:#1D3C5E">ICCV2025 @ Honolulu Hawaii</h1>
            <p style="font-size: 1.2rem; color:#1D3C5E">October 19, 2025</p>
            <a href="#cfp" class="cover-scroll-button">Call for Papers</a>
        </div>
    </section>

    <!-- Content Sections -->
    <section id="introduction" class="section">
        <div class="container">
            <h1>Introduction</h1>
            <p>Multimodal systems are transforming AI by enabling models to understand and act across language, vision, and other modalities, powering advances in robotics, autonomous driving, and scientific discovery. Yet, these capabilities raise serious safety and trustworthiness concerns, especially as traditional safeguards fall short in multimodal contexts. <b>The Workshop on Safe and Trustworthy Multimodal AI Systems (SaFeMM-AI) at ICCV 2025</b> brings together the computer vision community to address challenges, including and beyond hallucinations, privacy leakage, and jailbreak vulnerabilities, and advance the development of safer, more robust, and more reliable multimodal models.</p>
        </div>
    </section>

    <section id="important-dates" class="section">
        <div class="container">
            <h1>Important Deadlines</h1>
            <div class="wrapper">
                <ul class="sessions">
                <li>
                <div class="time"><s>June 19</s> June 27, 2025 (23:59 GMT)</div>
                <p class="subtitle"> Archival track - will appear in ICCV proceedings </p>
                <p>Full-Paper Submission</p>
                </li>
                <li>
                <div class="time"><s>July 11</s> July 14, 2025</div>
                <p>Full-Paper Notifications</p>
                </li>
                <li>
                <div class="time">August 15, 2025 (23:59 GMT)</div>
                <p class="subtitle"> Non-archival track - will NOT appear in ICCV proceedings </p>
                <p>Short-Paper Submission</p>
                </li>
                <li>
                <div class="time">August 18, 2025</div>
                <p>Camera-Ready Full-Paper (Archival Track)</p>
                </li>
                <li>
                <div class="time"><s>September 7</s> September 18, 2025</div>
                <p>Short-Paper Notifications</p>
                </li>
                <li>
                <div class="time">October 10, 2025</div>
                <p>Final Poster Submission</p>
                </li>
                <li>
                <div class="time">October 19, 2025</div>
                <p>Workshop Day</p>
                </li>
                </ul>
            </div>
        </div>
    </section>

    <!-- <section id="cfp" class="section">
        <div class="container">
            <h1>Call for Papers</h1>
            <p>Our workshop focuses on advancing the development of multimodal AI systems that can robustly handle unsafe or adversarial inputs and consistently generate safe, reliable, and trustworthy outputs. Topics of interest include but are not limited to:</p>
            <ul class="topics-list">
                <li>Reliability of multimodal systems, including hallucination detection and mitigation, toxic content prevention, interpretability, controllability, and stability in Multimodal Large Language Models (MLLMs) and agents</li>
                <li>Defenses against adversarial, backdoor, and jailbreak attacks in multimodal systems</li>
                <li>Prevention of misuse in multimodal systems, including privacy preservation, copyright protection, deepfake detection, bias elimination, and plagiarism detection</li>
                <li>Evaluation protocols and benchmarks for safety, fairness, and reliability in multimodal systems</li>
                <li>Safe usage and risk assessment of MLLMs and agents in high-stake domains (e.g., healthcare, chemistry, biology, robotics, autonomous driving)</li>
            </ul></br>
            <p><strong>Paper Submission Information for Short Paper (Active):</strong></p>
            <p>Submitted papers must be formatted using the <a href="https://media.eventhosts.cc/Conferences/ICCV2025/ICCV2025-Author-Kit-Feb.zip">ICCV 2025 Author Kit</a> 
                and are limited to four pages, including figures and tables. Additional pages are allowed only for references.
                We strongly encourage authors to carefully follow the <a href="https://iccv.thecvf.com/Conferences/2025/AuthorGuidelines">ICCV Author Guidelines</a>, since our workshop will adhere to the same formatting and submission policies as the main conference.
                Please check our <a href="resources/CFP/SaFeMM-AI_CFP_2025.pdf">Call for Papers document</a> which also applies to short paper submission except the page limit.
            <p>Accepted full paper submissions will be included in the official ICCV 2025 workshop proceedings. Both accepted full papers and short papers will be presented in the workshop poster session, so at least one author should register and present the poster.</p><br>
            <p><b>Note:</b> Submission of Full-paper (Archival track) has ended, submission platform is <b>currently open for short paper submissions only</b>.</p>
             <p><b>Note:</b> we also plan to open submissions for short papers (4 pages long) in July. These will not be included in the ICCV proceedings. More details on this will follow after the full paper deadline.</p> -->
            <!-- <div class="cfp-button-wrapper">
                <a href="https://openreview.net/group?id=thecvf.com/ICCV/2025/Workshop/SafeMM-AI" class="cover-scroll-button fancy-button">Submit Your Paper</a>
              </div> -->
        </div>
    </section>

    <section id="schedule" class="section">

        <div id="schedule-section">
            <!-- The schedule content will be inserted here dynamically -->
        </div>
        <div class="container">
            <h1>Schedule</h1>
            <div class="table_component" role="region" tabindex="0">
                <table>
                    <thead>
                      <tr>
                        <th>Time</th>
                        <th>Event</th>
                      </tr>
                    </thead>
                    <tbody>
                      <tr><td>9:00</td><td>Opening Remarks</td></tr>
                      <tr><td><strong>9:10</strong></td><td><strong><a href="#bengio">Prof. Yoshua Bengio: Avoiding Catastrophic Risks from Uncontrolled AI Agency</a></strong></td></tr>
                      <tr><td><strong>9:45</strong></td><td><strong><a href="#tramer">Prof. Florian Tram√®r: Memorization and Robustness in Multimodal Models</a></strong></td></tr>
                      <tr><td>10:20</td><td>Networking/Coffee Break</td></tr>
                      <tr><td><strong>10:55</strong></td><td><strong><a href="#gal">Prof. Yarin Gal: TBD</a></strong></td></tr>
                      <tr><td>11:30</td><td>Oral Presentation - Safety Without Semantic Disruptions: Editing-free Safe Image Generation via Context-preserving Dual Latent Reconstruction</td></tr>
                      <tr><td>11:45</td><td>Voxel51 - Sponsored Demo</td></tr>
                      <tr><td>12:00</td><td>Lunch Break</td></tr>
                      <tr><td>13:30</td><td>Oral Presentation - FrEVL: Leveraging Frozen Pretrained Embeddings for Efficient Vision-Language Understanding</td></tr>
                      <tr><td>13:45</td><td>Oral Presentation - Pulling Back the Curtain: Unsupervised Adversarial Detection via Contrastive Auxiliary Networks</td></tr>
                      <tr><td>14:00</td><td>Oral Presentation - On the Importance of Conditioning for Privacy-Preserving Data Augmentation</td></tr>
                      <tr><td><strong>14:15</strong></td><td><strong><a href="#qin">Prof. Yao Qin: TBD</a></strong></td></tr>
                      <tr><td>14:50</td><td>Oral Presentation - Superimposing 3D-models for Privacy in Videos for Self-Supervised Training</td></tr>
                      <tr><td>15:05</td><td>Closing Remarks</td></tr>
                      <tr><td>15:15</td><td>Poster Session & Networking/Coffee Break</td></tr>
                    </tbody>
                  </table>
                  </div>
              
        </div>
        <!-- <div class="container">
            <h2>Schedule</h2>
            <p>The detailed workshop schedule will be available closer to the event. Below is a general overview:</p>
            <ul>
                <li><strong>09:00 - 09:30:</strong> Registration and Breakfast</li>
                <li><strong>09:30 - 10:00:</strong> Opening Remarks</li>
                <li><strong>10:00 - 12:00:</strong> Keynote Speaker 1</li>
                <li><strong>12:00 - 13:30:</strong> Lunch</li>
                <li><strong>13:30 - 15:30:</strong> Paper Presentations - Session 1</li>
                <li><strong>15:30 - 16:00:</strong> Coffee Break</li>
                <li><strong>16:00 - 18:00:</strong> Paper Presentations - Session 2</li>
                <li><strong>18:00 - 18:30:</strong> Closing Remarks</li>
            </ul>
        </div> -->
    </section>

    <section id="speaker" class="section">
        <div class="container">
            <h1>Speakers</h1>
            <!-- Our amazing speakers will be announced soon. -->
            <div class="speaker-card" id="bengio">
                <img
                    src="resources/speaker/yoshua_bengio.jpg"
                    alt="Yoshua Bengio"
                    class="speaker-img"
                >
                <div class="speaker-info">
                    <a href="https://yoshuabengio.org/" target="_blank" rel="noopener">
                        <strong>Yoshua Bengio</strong>
                    </a>
                    <!-- <strong>Yoshua Bengio</strong> -->
                    <div class="speaker-affiliation">Full Professor - Mila, Universit√© de Montr√©al</div>
                    <!-- Tabs -->
                    <div class="tabs">
                        <button class="tab-button active" onclick="showTab(this, 'bio')">Bio</button>
                        <button class="tab-button" onclick="showTab(this, 'abstract')">Keynote</button>
                    </div>
                    <!-- Tab Content -->
                    <div class="tab-content active" data-tab="bio">
                    <p>
                        Yoshua Bengio is a world-leading expert in artificial intelligence, renowned for his pioneering work in deep learning, 
                        which earned him the 2018 A.M. Turing Award alongside Geoffrey Hinton and Yann LeCun. He is a Full Professor at Universit√© de 
                        Montr√©al, Founder and Scientific Advisor of <a href="https://mila.quebec/en">Mila</a> - Quebec AI Institute. He received numerous awards, including the prestigious 
                        Killam Prize and Herzberg Gold medal in Canada, CIFAR's AI Chair, Spain's Princess of Asturias Award, the VinFuture Prize and 
                        he is a Fellow of both the Royal Society of London and Canada, Knight of the Legion of Honor of France, Officer of the Order of 
                        Canada, Member of the UN's Scientific Advisory Board for Independent Advice on Breakthroughs in Science and Technology. 
                        Yoshua Bengio was named in 2024 as one of TIME magazine's 100 most influential people in the world. Concerned about the 
                        social impact of AI, he actively contributed to the Montreal Declaration for the Responsible Development of Artificial Intelligence 
                        and currently chairs the International Scientific Report on the Safety of Advanced AI. In June 2025, he launches a new non-profit AI safety research 
                        organization called <a href="https://lawzero.org/en">LawZero</a>, to prioritize safety over commercial imperatives.
                    </p>
                    </div>
                    <div class="tab-content" data-tab="abstract">
                        <p><b>Title: </b> Avoiding Catastrophic Risks from Uncontrolled AI Agency</p>
                        <p>
                            <b>Abstract:</b> AI agentic capabilities are rising exponentially, driven by scientific advances incorporating system 2 cognition into deep networks as well as by the commercial value of automating numerous human tasks. Besides bodily control, this may be the most significant gap that remains to human-level intelligence. Unfortunately, a series of recent scientific observations raise a major red flag: as AIs become better at reasoning and planning, more occurrences of deceptive and self-preservation behaviors are observed. We have not solved the problem of making sure that advanced AIs will follow our instructions, and in some circumstances they are found to cheat, lie, hack computers and try to escape our control, against their alignment training and instructions. Is it wise to design AIs that will soon be smarter than us across many cognitive abilities and could compete with us and try to avoid our control? We propose a safer path going forward: the design of non-agentic but fully trustworthy AIs modeled after a selfless platonic scientist trying to understand the world rather than trying to imitate or please us. For example, such non-agentic Scientist AIs could be used as monitors that reject potentially dangerous inputs or outputs of untrusted AI agents.
                        </p>
                    </div>
                </div>
            </div>
            <div class="speaker-card" id="gal">
                <img
                    src="resources/speaker/yarin_gal.jpg"
                    alt="Yarin Gal"
                    class="speaker-img"
                >
                <div class="speaker-info">
                    <a href="https://www.cs.ox.ac.uk/people/yarin.gal/website/" target="_blank" rel="noopener">
                        <strong>Yarin Gal</strong>
                    </a>
                    <!-- <strong>Yoshua Bengio</strong> -->
                    <div class="speaker-affiliation">Associate Professor - University of Oxford</div>
                    <div class="tabs">
                        <button class="tab-button active" onclick="showTab(this, 'bio')">Bio</button>
                        <button class="tab-button" onclick="showTab(this, 'abstract')">Keynote</button>
                    </div>
                    <!-- Tab Content -->
                    <div class="tab-content active" data-tab="bio">
                    <p>
                        Yarin leads the Oxford Applied and <a href="https://oatml.cs.ox.ac.uk/members/yarin/">Theoretical Machine Learning (OATML) group</a>. He is an Associate Professor of Machine Learning at the Computer Science department, University of Oxford. He is also the Tutorial Fellow in Computer Science at Christ Church, Oxford, a Turing AI Fellow at the Turing Institute, and Director of Research at the UK Government's AI Security Institute (AISI, formerly the Frontier AI Taskforce).
                        Prior to his move to Oxford he was a Research Fellow in Computer Science at St Catharine's College at the University of Cambridge. He obtained his PhD from the Cambridge machine learning group, working with Prof Zoubin Ghahramani and funded by the Google Europe Doctoral Fellowship.
                    </p>
                    </div>
                    <div class="tab-content" data-tab="abstract">
                        <p>
                           TBD
                        </p>
                      </div>

                </div>
            </div>
            <div class="speaker-card" id="tramer">
                <img
                    src="resources/speaker/florian.png"
                    alt="Florian Tram√®r"
                    class="speaker-img"
                >
                <div class="speaker-info">
                    <a href="https://floriantramer.com/" target="_blank" rel="noopener">
                        <strong>Florian Tram√®r</strong>
                    </a>
                    <div class="speaker-affiliation">Assistant Professor - ETH Z√ºrich</div>
                    <!-- Tabs -->
                    <div class="tabs">
                        <button class="tab-button active" onclick="showTab(this, 'bio')">Bio</button>
                        <button class="tab-button" onclick="showTab(this, 'abstract')">Keynote</button>
                    </div>
                  
                      <!-- Tab Content -->
                      <div class="tab-content active" data-tab="bio">
                        <p>
                            Florian Tram√®r is an Assistant Professor of Computer Science at ETH Z√ºrich, where he leads the <a href="https://spylab.ai/">Secure and Private AI (SPY) Lab</a>. 
                            He is a member of the Information Security Institute and ZISC, and an associated faculty member of the ETHZ AI Center. 
                            His research lies at the intersection of Computer Security, Machine Learning, and Cryptography. His work studies the worst-case 
                            behavior of deep learning systems from an adversarial perspective, aiming to understand and mitigate long-term threats to user 
                            safety and privacy. Under his leadership, the SPY Lab investigates the robustness and trustworthiness of machine learning systems, 
                            often using adversarial attacks to probe and improve their security.
                        </p>
                      </div>
                  
                      <div class="tab-content" data-tab="abstract">
                        <p><b>Title: </b>Memorization and Robustness in Multimodal Models</p>
                        <p><b>Abstract: </b>
                           In this talk, I'll cover some recent work on memorization and robustness in vision-language models. First, we'll discuss a curious phenomenon of "divergent memories" where VLMs can memorize data in one modality while having no concept of it in another. Second, we'll explore how techniques from the adversarial examples literature can be adapted to design efficient black-box attacks against VLMs.
                        </p>
                      </div>
                </div>
            </div>
            <div class="speaker-card" id="qin">
                <img
                    src="resources/speaker/yao_qin.jpg"
                    alt="Yao Qin"
                    class="speaker-img"
                >
                <div class="speaker-info">
                    <a href="https://yaoqin1.github.io/" target="_blank" rel="noopener">
                        <strong>Yao Qin</strong>
                    </a>
                    <!-- <strong>Yoshua Bengio</strong> -->
                    <div class="speaker-affiliation">Assistant Professor - UC Santa Barbara</div>
                    <div class="tabs">
                        <button class="tab-button active" onclick="showTab(this, 'bio')">Bio</button>
                        <button class="tab-button" onclick="showTab(this, 'abstract')">Keynote</button>
                    </div>
                    <!-- Tab Content -->
                    <div class="tab-content active" data-tab="bio">
                    <p>
                        Qin Yao is an Assistant Professor at the Department of Electrical and Computer Engineering, affiliated with the Department of Computer Science 
                        at UC Santa Barbara, where she is also co-leading the <a href="https://www.ai.ece.ucsb.edu/">REAL AI initiative</a>. Meanwhile, she is a senior 
                        Research Scientist at Google DeepMind, working on Gemini Multimodal. She obtained her PhD degree at UC San Diego in Computer Science, 
                        advised by Prof. Garrison W. Cottrell. During her PhD, she also interned under the supervision of Geoffrey Hinton, Ian Goodfellow and many others.
                    </p>
                    </div>
                    <div class="tab-content" data-tab="abstract">
                        <p>
                           TBD
                        </p>
                      </div>
                </div>
            </div>
        </div>
    </section>

    <section id="papers" class="section">
        <div class="container">
          <h1>Accepted Papers</h1>
          <div id="papers-list" class="papers-list"></div>
        </div>
    </section>
      

    <section id="committee" class="section">
        <div class="container">
            <h1>Organizers</h1>
            <div class="committee-grid">
                <div class="committee-member">
                    <img src="resources/committee/carlos_hinojosa.jpeg" alt="Main Organizer 1" class="profile-img">
                    <a href='https://carloshinojosa.me/'><strong>Carlos Hinojosa</strong></a> KAUST
                </div>
                <div class="committee-member">
                    <img src="resources/committee/yinpeng.jpeg" alt="Main Organizer 2" class="profile-img">
                    <a href='https://dongyp13.github.io'><strong>Yinpeng Dong</strong></a> Tsinghua University
                </div>
                <div class="committee-member">
                    <img src="resources/committee/adel_bibi.jpeg" alt="Main Organizer 3" class="profile-img">
                    <a href='https://www.adelbibi.com/'><strong>Adel Bibi</strong></a> University of Oxford
                </div>
                <div class="committee-member">
                    <img src="resources/committee/Jindong-Gu.jpeg" alt="Main Organizer 4" class="profile-img">
                    <a href='https://jindonggu.github.io'><strong>Jindong Gu</strong></a> University of Oxford
                </div>
                <div class="committee-member">
                    <img src="resources/committee/yichi-zhang.jpg" alt="Committee Member 1" class="profile-img">
                    <a href='https://zycheiheihei.github.io'><strong>Yichi Zhang</strong></a> Tsinghua University
                </div>
                <div class="committee-member">
                    <img src="resources/committee/wenxuan_zhang.png" alt="Committee Member 2" class="profile-img">
                    <a href='https://wx-zhang.github.io/'><strong>Wenxuan Zhang</strong></a> KAUST
                </div>
                <div class="committee-member">
                    <img src="resources/committee/lama.png" alt="Committee Member 3" class="profile-img">
                    <a href='https://cemse.kaust.edu.sa/profiles/lama-alssum'><strong>Lama Alssum </strong></a> KAUST
                </div>
                <div class="committee-member">
                    <img src="resources/committee/andres_villa.jpeg" alt="Committee Member 4" class="profile-img">
                    <a href='https://cemse.kaust.edu.sa/profiles/andres-villa'><strong>Andres Villa</strong></a> KAUST
                </div>
                <div class="committee-member">
                    <img src="resources/committee/juan_carlos.jpeg" alt="Committee Member 5" class="profile-img">
                    <a href='https://cemse.kaust.edu.sa/profiles/juan-carlos-l-alcazar'><strong>Juan Carlos L. Alcazar</strong></a> KAUST
                </div>
                <div class="committee-member">
                    <img src="resources/committee/Chen_Zhao.jpeg" alt="Committee Member 6" class="profile-img">
                    <a href='https://zhao-chen.com/'><strong>Chen Zhao</strong></a> KAUST
                </div>
                <div class="committee-member">
                    <img src="resources/committee/llv_clean_back1.jpeg" alt="Committee Member 7" class="profile-img">
                    <a href='https://sites.google.com/view/lingjuan-lyu/home'><strong>Lingjuan Lyu</strong></a> Sony
                </div>
                <div class="committee-member">
                    <img src="resources/committee/Mohamed_Elhoseiny.jpeg" alt="Committee Member 8" class="profile-img">
                    <a href='https://www.mohamed-elhoseiny.com/'><strong>Mohamed Elhoseiny</strong></a> KAUST
                </div>
                <div class="committee-member">
                    <img src="resources/committee/bernard_ghanem.jpeg" alt="Committee Member 9" class="profile-img">
                    <a href='https://www.bernardghanem.com/'><strong>Bernard Ghanem</strong></a> KAUST
                </div>
                <div class="committee-member">
                    <img src="resources/committee/phil-torr.jpg" alt="Committee Member 10" class="profile-img">
                    <a href='https://eng.ox.ac.uk/people/philip-torr/'><strong>Philip Torr</strong></a> University of Oxford
                </div>
                <!-- Additional members can be added here in a similar manner -->
            </div>
        </div>
    </section>

    <!-- <section id="contact" class="section">
        <div class="container">
            <h1>Sponsors</h1>
            <p>We are sincerely grateful for the supports from all our sponsors.</p>
            <div class="committee-grid" style="margin-top: 3vh; background-color: #fff;">
                <div class="committee-member" style="flex-wrap: wrap;">
                    <img src="resources/sponsor/bosch.png" alt="Sponsor 0" style="background-color: #fff; width: 100%;;">
                </div>
                <div class="committee-member" style="flex-wrap: wrap;">
                    <img src="resources/sponsor/alibaba.png" alt="Sponsor 0" style="background-color: #fff; width: 80%; margin-top: 5%;">
                </div>
                <div class="committee-member" style="flex-wrap: wrap;">
                    <img src="resources/sponsor/horizon.png" alt="Sponsor 0" style="background-color: #fff; width: 100%; margin-top: 5%;">
                </div>
            </div>
        </div>
    </section> -->
    
    <section id="contact" class="section">
        <div class="container">
            <h1>Contact</h1>
            <p>
              Stay up to date by following us on 
              <i class="fa fa-twitter" aria-hidden="true" style="color:#1DA1F2;"></i>
              <a href="https://x.com/SaFeMMAI">@SaFeMMAI</a>.
            </p>
            <p><i class="fa fa-envelope" aria-hidden="true" style="color:#FF5E3A; margin-right: 0.4em;"></i>For any inquiries, feel free to reach out to us via email at: <a href="mailto:safemm.ai.workshop@gmail.com">safemm.ai.workshop@gmail.com.</a> or You may also contact the organizers directly: <a href="mailto:carlos.hinojosa@kaust.edu.sa">Carlos Hinojosa</a>, and <a href="dongyinpeng@mail.tsinghua.edu.cn">Yinpeng Dong</a>.</p>
        </div>
    </section>

    <section id="sponsorship" class="section">
        <div class="container">
            <h1>Sponsors</h1>
            <!-- <p>We are seeking sponsors to help fund travel grants, the best paper award, and other workshop initiatives. If you or your organization is interested in supporting SEA, please reach out to the organizing team via email (<a href="mailto:safemm.ai.workshop@gmail.com">safemm.ai.workshop@gmail.com).</a></p> -->
            <p>We sincerely thank our sponsors for their generous support of the SaFeMM-AI workshop at ICCV 2025.</p>
            <!-- Link the logo to the sponsor‚Äôs site (optional but typical) -->
            <a href="https://voxel51.com/"
            class="sponsors__logo"
            target="_blank" rel="noopener">
            <!-- 1√ó/2√ó (retina) versions served automatically via srcset.  
                Width/height help browsers reserve space before the file loads. -->
            <img
            src="resources/sponsor/voxel51.svg"
            alt="Sponsor Name logo"
            width="160" height="48"
            loading="lazy">
            </a>
            <a href="https://bayou-ai.com/"
            class="sponsors__logo"
            target="_blank" rel="noopener" style="padding-left: 2rem;">
            <!-- 1√ó/2√ó (retina) versions served automatically via srcset.  
                Width/height help browsers reserve space before the file loads. -->
            <img
            src="resources/sponsor/bayou.png"
            alt="Sponsor Name logo"
            width="160" height="48"
            loading="lazy">
            </a>
            <a href="https://www.toyota-europe.com/"
            class="sponsors__logo"
            target="_blank" rel="noopener" style="padding-left: 2rem;">
            <!-- 1√ó/2√ó (retina) versions served automatically via srcset.  
                Width/height help browsers reserve space before the file loads. -->
            <img
            src="resources/sponsor/toyota.png"
            alt="Sponsor Name logo"
            width="160" height="48"
            loading="lazy">
            </a>
        </div>
    </section>

    <footer>
        <div class="container">
            <p>&copy; 2025 SaFeMM-AI Workshop. All rights reserved.</p>
        </div>
    </footer>
</body>

</html>

<script>

/* When the user clicks on the button,
toggle between hiding and showing the dropdown content */
function myFunction(event) {
    event.stopPropagation(); // üß† stops window click handler
    document.getElementById("myDropdown").classList.toggle("show");
}

function Close() {
    var dropdowns = document.getElementsByClassName("dropdown-content");
    var i;
    for (i = 0; i < dropdowns.length; i++) {
      var openDropdown = dropdowns[i];
      if (openDropdown.classList.contains('show')) {
        openDropdown.classList.remove('show');
      }
    }
}

// Close the dropdown menu if the user clicks outside of it
window.onclick = function(event) {
  if (!event.target.matches('.dropbtn')) {
    var dropdowns = document.getElementsByClassName("dropdown-content");
    var i;
    for (i = 0; i < dropdowns.length; i++) {
      var openDropdown = dropdowns[i];
      if (openDropdown.classList.contains('show')) {
        openDropdown.classList.remove('show');
      }
    }
  }
}


function showTab(button, tabKey) {
  const card = button.closest('.speaker-card'); // Get the card where the button was clicked

  const buttons = card.querySelectorAll('.tab-button');
  const contents = card.querySelectorAll('.tab-content');

  // Remove active class from all buttons & contents
  buttons.forEach(btn => btn.classList.remove('active'));
  contents.forEach(content => content.classList.remove('active'));

  // Activate the clicked tab and corresponding content
  button.classList.add('active');
  card.querySelector(`.tab-content[data-tab="${tabKey}"]`).classList.add('active');
}

// Load and render accepted papers from CSV
async function loadAcceptedPapers() {
  console.log("hello")
  const response = await fetch('./resources/accepted_papers.json'); // Path to your CSV
  const accepted = await response.json()
  const papersList = document.getElementById('papers-list');

  const posterList = [
    "HalluSegBench_SafeMMAI_Poster.pdf",
    "Navtrust_Safemmai_poster.pdf",
    "pulling_back_the_courtain.pdf",
    "Revisiting_Safemmai_poster.pdf",
    "SIFT-Graph_safemmai_poser.pdf"
  ];

  accepted.forEach((pub, index) => {
    const number = pub.number;
    const type = pub.type;
    const title = pub.title;
    const authors = pub.authors;
    const abstract = pub.abstract; // in case abstract contains commas

    console.log(title)

    // posterList.forEach((p) => {
    //     console.log(p)
    //     console.log(p.toLowerCase().split('_')[0])
    // })
    const match = posterList.find(p =>
      title.toLowerCase().startsWith(p.toLowerCase().split('_')[0]) // match by prefix
    );

    console.log(match)

    const posterLink = match
      ? `<p><a href="./resources/posters/${match}" target="_blank" class="poster-link">üìÑ View Poster</a></p>`
      : "";

    const item = document.createElement('div');
    item.classList.add('paper-item');
    item.innerHTML = `
      <div class="paper-header">
        <div class="paper-title">${title}</div>
        <div class="paper-type">${type.toUpperCase()}</div>
    </div>
      <div class="paper-details">
        <p><strong>Authors:</strong> ${authors}</p>
        <p><strong>Abstract:</strong> ${abstract}</p>
        ${posterLink}
      </div>
    `;
    item.addEventListener('click', () => {
    const details = item.querySelector('.paper-details');
    const isOpen = item.classList.toggle('open');

    if (isOpen) {
        // Expand smoothly to the element‚Äôs actual height
        details.style.maxHeight = details.scrollHeight + 'px';
    } else {
        // Collapse back smoothly
        details.style.maxHeight = null;
    }
    });
    papersList.appendChild(item);
  });
}

window.onload = loadAcceptedPapers;


</script>
